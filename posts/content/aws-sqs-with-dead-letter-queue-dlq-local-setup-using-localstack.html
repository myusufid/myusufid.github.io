<!--
title: AWS SQS with Dead-letter queue (DLQ) local setup using Localstack
description: A comprehensive guide on how to set up AWS SQS with DLQ locally using Localstack for robust development and testing.
date: 2025-08-26
tags: aws, sqs, dlq, localstack, docker, python, microservices, distributed-systems, go, lambda
-->
<article class="blog-post">
    <h1>AWS SQS with Dead-letter queue (DLQ) local setup using Localstack</h1>
    <div class="meta mb-4">2025-08-26</div>

    <p>Developing and testing distributed systems can be a complex and challenging task. These systems are composed of multiple services that communicate with each other asynchronously, often through message queues. AWS Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. However, relying solely on the cloud for development and testing can be slow and expensive. This is where Localstack comes in.</p>

    <p>Localstack is a high-fidelity local AWS cloud stack that allows you to develop and test your cloud and serverless applications offline. By using Localstack, you can significantly speed up your development and testing cycles, reduce costs, and improve the overall quality of your applications. In this comprehensive guide, we will walk you through the process of setting up AWS SQS with a Dead-Letter Queue (DLQ) locally using Localstack. We will cover everything from setting up your local environment to creating a realistic case study that demonstrates how to handle message processing failures.</p>

    <h2>Local Development Setup</h2>

    <p>Before we dive into the details of setting up SQS with a DLQ, let's first set up our local development environment. You will need to have Docker and Docker Compose installed on your machine. If you don't have them installed, you can follow the official documentation to install them:</p>

    <ul>
        <li><a href="https://docs.docker.com/get-docker/" target="_blank" rel="noopener noreferrer">Install Docker</a></li>
        <li><a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Install Docker Compose</a></li>
    </ul>

    <p>Once you have Docker and Docker Compose installed, create a new directory for your project and create a file named <code>docker-compose.localstack.yml</code> with the following content:</p>

    <pre><code class="language-yaml">
version: '3.8'

services:
  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"
      - "4510-4559:4510-4559"
    environment:
      - SERVICES=sqs,iam,lambda
      - DEFAULT_REGION=us-east-1
    volumes:
      - "${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"
    </code></pre>

    <p>This Docker Compose file is slightly different from the previous example. It uses a more recent version of Localstack and explicitly enables the <code>iam</code> and <code>lambda</code> services, which we'll need for our advanced case study.</p>

    <p>You can start Localstack by running:</p>
    <pre><code class="language-bash">
docker-compose -f docker-compose.localstack.yml up -d
    </code></pre>

    <h2>Creating the SQS Queues</h2>

    <p>While you can use an initialization script as shown previously, you can also create resources manually using the AWS CLI. First, let's configure a local profile for the AWS CLI to interact with Localstack easily.</p>

    <pre><code class="language-bash">
aws configure set aws_access_key_id test --profile local && \
aws configure set aws_secret_access_key test --profile local && \
aws configure set region us-east-1 --profile local && \
aws configure set output json --profile local
    </code></pre>

    <p>Now, let's create our FIFO queue and its corresponding Dead-Letter Queue (DLQ). We are using FIFO queues for ordering and exactly-once processing guarantees.</p>

    <pre><code class="language-bash">
# Create FIFO SQS queue with ContentBasedDeduplication enabled
aws --endpoint-url=http://localhost:4566 --profile local sqs create-queue \
  --queue-name simple-queue.fifo \
  --attributes FifoQueue=true,ContentBasedDeduplication=true,VisibilityTimeout=60

# Create DLQ (Dead Letter Queue) for failed messages
aws --endpoint-url=http://localhost:4566 --profile local sqs create-queue \
  --queue-name simple-queue-dlq.fifo \
  --attributes FifoQueue=true,ContentBasedDeduplication=true
    </code></pre>

    <h3>Dead-Letter Queues (DLQs)</h3>

    <p>A Dead-Letter Queue (DLQ) is a queue that other (source) queues can target for messages that can't be processed successfully. DLQs are useful for debugging your application or messaging system because they let you isolate unconsumed messages to determine why their processing failed. When you configure a DLQ, you need to set a redrive policy on the source queue. The redrive policy specifies the ARN of the DLQ and the <code>maxReceiveCount</code>, which is the number of times a message can be received by consumers before it's sent to the DLQ.</p>

    <h3>Visibility Timeout</h3>

    <p>The visibility timeout is the period of time during which Amazon SQS prevents other consumers from receiving and processing a message. The default visibility timeout for a message is 30 seconds. The minimum is 0 seconds. The maximum is 12 hours. When a consumer receives a message, the visibility timeout for that message begins. If the consumer fails to process and delete the message before the visibility timeout expires, the message becomes visible to other consumers and can be received again. In our script, we set the visibility timeout to 60 seconds.</p>

    <h2>Advanced Case Study: Go Lambda Producer/Consumer</h2>
    <p>Let's build a more advanced, serverless example using Go Lambda functions to produce and consume messages. This mimics a more realistic microservices architecture.</p>

    <h3>Step 1: The SQS Sender Lambda (Go)</h3>
    <p>First, we'll create a Lambda function that sends a message to our <code>simple-queue.fifo</code>.</p>
    <p>Compile the Go application for a Linux environment and create a deployment package:</p>
    <pre><code class="language-bash">
# Build the Go binary
GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o lambda/handlers/simple_sqs_sender/bootstrap lambda/handlers/simple_sqs_sender/main.go lambda/handlers/simple_sqs_sender/localstack_sqs.go

# Create deployment package
chmod +x lambda/handlers/simple_sqs_sender/bootstrap
cd lambda/handlers/simple_sqs_sender && zip simple_sqs_sender.zip bootstrap && cd ../../..
    </code></pre>

    <p>Next, create an IAM role that the Lambda function can assume to get permissions to send messages to SQS.</p>
    <pre><code class="language-bash">
# Create IAM Role for the sender Lambda
aws --endpoint-url=http://localhost:4566 --profile local iam create-role \
  --role-name lambda-sqs-role \
  --assume-role-policy-document '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"lambda.amazonaws.com"},"Action":"sts:AssumeRole"}]}'

# Attach a policy to the role
aws --endpoint-url=http://localhost:4566 --profile local iam put-role-policy \
  --role-name lambda-sqs-role \
  --policy-name SQSAccessPolicy \
  --policy-document '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Action":["sqs:SendMessage"],"Resource":"*"}]}'
    </code></pre>

    <p>Finally, create the Lambda function itself.</p>
    <pre><code class="language-bash">
# Create the sender Lambda function
aws --endpoint-url=http://localhost:4566 --profile local lambda create-function \
  --function-name simple-sqs-sender \
  --runtime provided.al2 \
  --role arn:aws:iam::000000000000:role/lambda-sqs-role \
  --handler bootstrap \
  --zip-file fileb://lambda/handlers/simple_sqs_sender/simple_sqs_sender.zip \
  --timeout 30 \
  --architectures x86_64 \
  --environment Variables='{SQS_SIMPLE_QUEUE_URL=http://sqs.us-east-1.localhost.localstack.cloud:4566/000000000000/simple-queue.fifo,AWS_ENDPOINT_URL=http://host.docker.internal:4566}'
    </code></pre>
    <p>Note the environment variables. We pass the queue URL and the AWS endpoint URL so the Lambda knows where to send messages within the Localstack environment.</p>

    <h3>Step 2: The SQS Receiver Lambda (Go)</h3>
    <p>Now, let's create the consumer. This Lambda will be triggered by messages arriving in <code>simple-queue.fifo</code>.</p>
    <p>First, build and package the receiver application:</p>
    <pre><code class="language-bash">
# Build the Go binary
GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o lambda/handlers/simple_sqs_receiver/bootstrap lambda/handlers/simple_sqs_receiver/main.go

# Create deployment package
chmod +x lambda/handlers/simple_sqs_receiver/bootstrap
cd lambda/handlers/simple_sqs_receiver && zip simple_sqs_receiver.zip bootstrap && cd ../../..
    </code></pre>

    <p>Create the necessary IAM role and policy for the receiver to read and delete messages from the queue.</p>
    <pre><code class="language-bash">
# Create IAM Role for the receiver Lambda
aws --endpoint-url=http://localhost:4566 --profile local iam create-role \
  --role-name lambda-sqs-receiver-role \
  --assume-role-policy-document '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"lambda.amazonaws.com"},"Action":"sts:AssumeRole"}]}'

# Attach a policy to the role
aws --endpoint-url=http://localhost:4566 --profile local iam put-role-policy \
  --role-name lambda-sqs-receiver-role \
  --policy-name SQSReceiverPolicy \
  --policy-document '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Action":["sqs:ReceiveMessage","sqs:DeleteMessage","sqs:GetQueueAttributes"],"Resource":"*"}]}'
    </code></pre>

    <p>Create the receiver Lambda function:</p>
    <pre><code class="language-bash">
# Create the receiver Lambda function
aws --endpoint-url=http://localhost:4566 --profile local lambda create-function \
  --function-name simple-sqs-receiver \
  --runtime provided.al2 \
  --role arn:aws:iam::000000000000:role/lambda-sqs-receiver-role \
  --handler bootstrap \
  --zip-file fileb://lambda/handlers/simple_sqs_receiver/simple_sqs_receiver.zip \
  --timeout 30 \
  --architectures x86_64 \
  --environment Variables='{AWS_ENDPOINT_URL=http://host.docker.internal:4566}'
    </code></pre>

    <h3>Step 3: Configure Redrive and Event Source Mapping</h3>
    <p>Now we connect the main queue to its DLQ. Create a file named <code>redrive-attributes.json</code> with the following content. This tells <code>simple-queue.fifo</code> to send messages to <code>simple-queue-dlq.fifo</code> after they have been received twice without being deleted.</p>
    <pre><code class="language-json">
{
    "RedrivePolicy": "{\"deadLetterTargetArn\":\"arn:aws:sqs:us-east-1:000000000000:simple-queue-dlq.fifo\",\"maxReceiveCount\":\"2\"}"
}
    </code></pre>
    <p>Apply this policy to the main queue:</p>
    <pre><code class="language-bash">
aws --endpoint-url=http://localhost:4566 --profile local sqs set-queue-attributes \
  --queue-url http://localhost:4566/000000000000/simple-queue.fifo \
  --attributes file://redrive-attributes.json
    </code></pre>

    <p>Finally, create an event source mapping. This crucial step subscribes the <code>simple-sqs-receiver</code> Lambda to the <code>simple-queue.fifo</code> queue. AWS Lambda will now poll the queue and invoke your function when messages are available.</p>
    <pre><code class="language-bash">
aws --endpoint-url=http://localhost:4566 --profile local lambda create-event-source-mapping \
  --function-name simple-sqs-receiver \
  --event-source-arn arn:aws:sqs:us-east-1:000000000000:simple-queue.fifo \
  --batch-size 1
    </code></pre>

    <p>With this setup, you can invoke the <code>simple-sqs-sender</code> Lambda to send messages. The <code>simple-sqs-receiver</code> will be triggered automatically. If the receiver fails to process a message twice, it will be moved to the DLQ for later inspection.</p>

    <h2>Benefits of Using a DLQ</h2>

    <ul>
        <li><strong>Improved Reliability:</strong> DLQs help to ensure that messages are not lost due to processing failures.</li>
        <li><strong>Easier Debugging:</strong> DLQs make it easier to debug and troubleshoot message processing failures by isolating the failed messages.</li>
        <li><strong>Increased Resilience:</strong> DLQs can help to make your applications more resilient to transient failures.</li>
    </ul>

    <h2>Conclusion</h2>

    <p>In this comprehensive guide, we have shown you how to set up AWS SQS with a Dead-Letter Queue (DLQ) locally using Localstack. We have covered everything from setting up your local environment to creating a realistic case study that demonstrates how to handle message processing failures. By using Localstack, you can significantly speed up your development and testing cycles, reduce costs, and improve the overall quality of your applications.</p>

    <p>For more information, you can refer to the following resources:</p>

    <ul>
        <li><a href="https://docs.localstack.cloud/" target="_blank" rel="noopener noreferrer">Localstack Documentation</a></li>
        <li><a href="https://aws.amazon.com/sqs/" target="_blank" rel="noopener noreferrer">AWS SQS Documentation</a></li>
    </ul>
</article>